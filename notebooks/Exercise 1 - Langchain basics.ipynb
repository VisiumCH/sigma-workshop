{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic fighters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 - LangChain basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Chatbot simple\n",
    "\n",
    "Bienvenidos a la primera parte del workshop!\n",
    "\n",
    "Vamos a empezar viendo cómo podemos generar una aplicación basada en IA que utilice LangChain, un framework muy popular para desarrollar apps con LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparar las claves\n",
    "\n",
    "Primero, vamos a preparar el entorno de Python para poder usar las claves de OpenAI. Hay que definir la OPENAI_API_KEY en el archivo .env.\n",
    "\n",
    "El código busca la clave y fija unos parámetros:\n",
    "\n",
    "- LLM_MODEL: el modelo a utilizar\n",
    "- LLM_TEMPERATURE: parámetro que controla la aleatoriedad de las respuestas (0 significa que será completamente determinista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Please set OPENAI_API_KEY environment variable\")\n",
    "\n",
    "LLM_MODEL = \"gpt-4o-mini\"\n",
    "LLM_TEMPERATURE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a crear el chabot con LangChain. Usaremos:\n",
    "\n",
    "- ChatOpenAI: la interfaz a los modelos de OpenAI\n",
    "- SystemMessage: define el comportamiento general del modelo\n",
    "- HumanMessage: representa el input del usuario\n",
    "\n",
    "Vamos a crear un chatbot con la temática deseada. Para ello:\n",
    "\n",
    "1. instanciamos el modelo\n",
    "2. definimos el system prompt que define el rol del chatbot\n",
    "3. enviamos una query y recibimos una respuesta con el método .invoke()\n",
    "\n",
    "Así vemos el patrón básico de interacciones: prompt → respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x1092f4990>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x1092fc790>, root_client=<openai.OpenAI object at 0x108666f10>, root_async_client=<openai.AsyncOpenAI object at 0x108fdd710>, model_name='gpt-4o-mini', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Create a ChatOpenAI instance with the LLM model and temperature\n",
    "base_model = ChatOpenAI(model=LLM_MODEL, temperature=LLM_TEMPERATURE)\n",
    "base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PROMPT = \"\"\"\n",
    "Eres un profesor de la UPV y te gusta que todos los alumnos aprendan.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='\\nEres un profesor de la UPV y te gusta que todos los alumnos aprendan.\\n', additional_kwargs={}, response_metadata={}), HumanMessage(content=' Explicame que es un agente en tematica de IA y data science', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "# Request from the client\n",
    "request = \" Explicame que es un agente en tematica de IA y data science\"\n",
    "\n",
    "# Message list for the base model\n",
    "messages = [\n",
    "    SystemMessage(BASE_PROMPT),\n",
    "    HumanMessage(request),\n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the model with the messages\n",
    "response = base_model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "En el contexto de la inteligencia artificial (IA) y la ciencia de datos, un \"agente\" se refiere a una entidad que puede percibir su entorno a través de sensores y actuar sobre ese entorno mediante actuadores. Los agentes pueden ser tanto físicos (como robots) como virtuales (como programas de software).\n",
       "\n",
       "### Características de un Agente:\n",
       "\n",
       "1. **Percepción**: Un agente tiene la capacidad de recibir información del entorno. Esto puede incluir datos de sensores, entradas de usuario, o información de otras fuentes.\n",
       "\n",
       "2. **Acción**: Basándose en la información percibida, un agente puede tomar decisiones y realizar acciones. Estas acciones pueden ser la ejecución de comandos, la modificación de datos, o la interacción con otros agentes.\n",
       "\n",
       "3. **Autonomía**: Muchos agentes operan de manera autónoma, lo que significa que pueden tomar decisiones sin intervención humana. Sin embargo, también pueden ser diseñados para trabajar en colaboración con humanos.\n",
       "\n",
       "4. **Adaptabilidad**: Algunos agentes son capaces de aprender de su experiencia y adaptarse a cambios en el entorno. Esto se logra a menudo mediante técnicas de aprendizaje automático.\n",
       "\n",
       "5. **Objetivos**: Los agentes suelen tener objetivos específicos que buscan alcanzar. Estos objetivos pueden ser definidos explícitamente por un programador o pueden ser aprendidos a través de la experiencia.\n",
       "\n",
       "### Tipos de Agentes:\n",
       "\n",
       "1. **Agentes Reactivos**: Responden a estímulos del entorno sin un modelo interno del mismo. Su comportamiento es generalmente simple y basado en reglas.\n",
       "\n",
       "2. **Agentes Basados en Modelos**: Mantienen un modelo interno del entorno que les permite hacer inferencias y tomar decisiones más complejas.\n",
       "\n",
       "3. **Agentes de Aprendizaje**: Utilizan técnicas de aprendizaje automático para mejorar su rendimiento a lo largo del tiempo, adaptándose a nuevas situaciones y optimizando sus acciones.\n",
       "\n",
       "4. **Agentes Multiagente**: Sistemas que involucran múltiples agentes que interactúan entre sí, lo que puede dar lugar a comportamientos emergentes y soluciones más complejas.\n",
       "\n",
       "### Ejemplos de Agentes en IA y Ciencia de Datos:\n",
       "\n",
       "- **Asistentes Virtuales**: Como Siri o Alexa, que perciben comandos de voz y responden con acciones o información.\n",
       "- **Sistemas de Recomendación**: Que analizan datos de usuarios para sugerir productos o contenidos.\n",
       "- **Robots Autónomos**: Que navegan en entornos físicos, como drones o vehículos autónomos.\n",
       "- **Chatbots**: Que interactúan con usuarios en plataformas de mensajería, respondiendo preguntas y realizando tareas.\n",
       "\n",
       "En resumen, un agente en IA y ciencia de datos es una entidad que percibe su entorno, toma decisiones y actúa en consecuencia, con el objetivo de lograr metas específicas. Su diseño y funcionalidad pueden variar ampliamente dependiendo de la aplicación y el contexto en el que se utilicen."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Prompt template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain proporciona formas de manejar los prompts, para ser consistente y con ello poder parsear resultados convenientemente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_string = \"\"\"Traduce el texto entre comillas simples al {target_language}:\n",
    "'{input_text}'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input_text', 'target_language'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_text', 'target_language'], input_types={}, partial_variables={}, template=\"Traduce el texto entre comillas simples al {target_language}:\\n'{input_text}'\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input_text', 'target_language'], input_types={}, partial_variables={}, template=\"Traduce el texto entre comillas simples al {target_language}:\\n'{input_text}'\\n\")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_text', 'target_language']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_language = \"English\"\n",
    "input_text = \"Estamos haciendo un workshop en la UPV para aprender sobre agentes y poder desarrollar una app generativa de peleas!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Traduce el texto entre comillas simples al English:\\n'Estamos haciendo un workshop en la UPV para aprender sobre agentes y poder desarrollar una app generativa de peleas!'\\n\", additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = prompt_template.format_messages(input_text=input_text, target_language=target_language)\n",
    "print(type(message))\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content=\"Traduce el texto entre comillas simples al English:\\n'Estamos haciendo un workshop en la UPV para aprender sobre agentes y poder desarrollar una app generativa de peleas!'\\n\", additional_kwargs={}, response_metadata={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"'We are holding a workshop at UPV to learn about agents and to be able to develop a generative fighting app!'\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 43, 'total_tokens': 69, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None} id='run-d97d21b4-7910-44fe-9710-ee2581573816-0' usage_metadata={'input_tokens': 43, 'output_tokens': 26, 'total_tokens': 69, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "'We are holding a workshop at UPV to learn about agents and to be able to develop a generative fighting app!'"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = base_model.invoke(message)\n",
    "print(response)\n",
    "Markdown(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto nos devuelve una respuesta del tipo _AIMessage_. Pero vamos a ver si lo que queremos es parsearla y que devuelva un JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "prompt_template_json = copy.deepcopy(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Traduce el texto entre comillas simples al {target_language}:\\n'{input_text}'\\n. Crea la respuesta en formato JSON, con claves 'idioma_original' y 'traducido'\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_json.messages[0].prompt.template = f\"{prompt_template.messages[0].prompt.template}. Crea la respuesta en formato JSON, con claves 'idioma_original' y 'traducido'\"\n",
    "prompt_template_json.messages[0].prompt.template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n  \"idioma_original\": \"\\'Estamos haciendo un workshop en la UPV para aprender sobre agentes y poder desarrollar una app generativa de peleas!\\'\",\\n  \"traducido\": \"We are doing a workshop at UPV to learn about agents and to be able to develop a generative fighting app!\"\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 69, 'prompt_tokens': 65, 'total_tokens': 134, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_00428b782a', 'finish_reason': 'stop', 'logprobs': None}, id='run-f184a442-b0a1-49db-a463-256dfecfb7bf-0', usage_metadata={'input_tokens': 65, 'output_tokens': 69, 'total_tokens': 134, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message = prompt_template_json.format_messages(input_text=input_text, target_language=target_language)\n",
    "response = base_model.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraducido\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "response.content.get(\"traducido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No se ha generado un JSON, sino que es un string con un formato similar.\n",
    "\n",
    "Vamos a ver qué podemos hacer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ResponseSchema(name='idioma_original', description='The original text', type='string'),\n",
       " ResponseSchema(name='traducido', description='The translated text', type='string')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_schema = [\n",
    "    ResponseSchema(name=\"idioma_original\", description=\"The original text\"),\n",
    "    ResponseSchema(name=\"traducido\", description=\"The translated text\"),\n",
    "]\n",
    "response_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredOutputParser(response_schemas=[ResponseSchema(name='idioma_original', description='The original text', type='string'), ResponseSchema(name='traducido', description='The translated text', type='string')])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schema)\n",
    "output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
       "\n",
       "```json\n",
       "{\n",
       "\t\"idioma_original\": string  // The original text\n",
       "\t\"traducido\": string  // The translated text\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_intructions = output_parser.get_format_instructions()\n",
    "Markdown(format_intructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Traduce el texto entre comillas simples al English:\\n\\'Estamos haciendo un workshop en la UPV para aprender sobre agentes y poder desarrollar una app generativa de peleas!\\'.\\n\\nThe output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"idioma_original\": string  // The original text\\n\\t\"traducido\": string  // The translated text\\n}\\n```\\n', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_json_format = \"\"\"Traduce el texto entre comillas simples al {target_language}:\n",
    "'{input_text}'.\n",
    "\n",
    "{format_intructions}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template_json_format)\n",
    "message = prompt.format_messages(input_text=input_text, target_language=target_language, format_intructions=format_intructions)\n",
    "print(type(message))\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='```json\\n{\\n\\t\"idioma_original\": \"Estamos haciendo un workshop en la UPV para aprender sobre agentes y poder desarrollar una app generativa de peleas!\",\\n\\t\"traducido\": \"We are doing a workshop at UPV to learn about agents and to be able to develop a generative fighting app!\"\\n}\\n```', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 68, 'prompt_tokens': 104, 'total_tokens': 172, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_13eed4fce1', 'finish_reason': 'stop', 'logprobs': None}, id='run-ac5c875e-6a2c-4e7a-b1b0-e03147b5ab08-0', usage_metadata={'input_tokens': 104, 'output_tokens': 68, 'total_tokens': 172, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = base_model.invoke(message)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idioma_original': 'Estamos haciendo un workshop en la UPV para aprender sobre agentes y poder desarrollar una app generativa de peleas!',\n",
       " 'traducido': 'We are doing a workshop at UPV to learn about agents and to be able to develop a generative fighting app!'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict = output_parser.parse(response.content)\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We are doing a workshop at UPV to learn about agents and to be able to develop a generative fighting app!'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict.get(\"traducido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra: Chains -> LangChain Expression Language (LCEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las cadenas eran el elemento básico de LangChain, que nos permiten ejecutar prompts uno detrás de otro (o con la estructura definida).\n",
    "\n",
    "Hoy en día estan deprecadas. Son interesantes de conocer, pero ahora todo se basa en Runnables, que es lo que utiliza LangGraph. Pasamos directamente a ello."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
